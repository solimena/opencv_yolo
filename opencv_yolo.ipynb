{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This project provides an automated image processing pipeline designed to detect and center people in photos. Using YOLOv8 for detection and OpenCV for manipulation, the pipeline ensures consistent output by resizing, cropping, and centering individuals in images. Key features include:\n",
        "\n",
        "*   Precise Detection: Identifies and localizes people in images.\n",
        "*   Scaling and Cropping: Adjusts images to a fixed aspect ratio (3:4) and centers the subject.\n",
        "*   Easy Configuration: Customizable parameters for bounding box height and crop dimensions.\n",
        "\n",
        "This notebook enables quick setup and execution of the pipeline directly in Colab, making it ideal for processing images with minimal local setup."
      ],
      "metadata": {
        "id": "OXWMnLAiT-mu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation Step: Install Required Libraries\n",
        "\n",
        "\n",
        "Before running the image processing pipeline, we need to ensure all necessary libraries are installed. The following lines perform the setup:\n",
        "\n",
        "```\n",
        "!pip install opencv-python opencv-python-headless\n",
        "```\n",
        "\n",
        "* **Installs OpenCV**: This library is used for reading, manipulating, and saving images. The opencv-python-headless variant is designed for environments without GUI support, such as Colab.\n",
        "\n",
        "```\n",
        "!pip install mediapipe`\n",
        "```\n",
        "\n",
        "* **Installs MediaPipe**: Although not directly used in this script, MediaPipe is a framework for building multimodal (e.g., face, hands, or pose) tracking solutions and might complement YOLO-based detection in future extensions.\n",
        "\n",
        "```\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "```\n",
        "\n",
        "\n",
        "* **Installs Ultralytics**: Provides access to the YOLOv8 object detection framework, which is essential for detecting persons in the images.\n",
        "Runtime Environment Settings\n",
        "Ensure your Colab runtime is configured as follows:\n",
        "\n",
        "* **Runtime Type**: Python 3\n",
        "* **Hardware Accelerator**: CPU\n",
        "\n",
        "These settings are sufficient for the pipeline since the processing is optimized for environments without GPU support. If GPU-based enhancements (e.g., Real-ESRGAN) are integrated in the future, the hardware accelerator can be switched to GPU."
      ],
      "metadata": {
        "id": "jHr-bvo5UziV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python opencv-python-headless\n",
        "!pip install mediapipe\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ2mCLg55hoD",
        "outputId": "cc03d229-4166-4d9f-fb1f-ed76fa4fa2ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.12.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.20-cp310-cp310-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.20 sounddevice-0.5.1\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.59-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.59-py3-none-any.whl (906 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.8/906.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.59 ultralytics-thop-2.0.13\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration and Global Variables\n",
        "This section sets up key parameters for the image processing pipeline:\n",
        "\n",
        "\n",
        "```\n",
        "desired_box_height = 2600\n",
        "crop_width = 1920\n",
        "crop_height = 2700\n",
        "```\n",
        "\n",
        "* **desired_box_height**: Ensures the detected person occupies 2600 pixels vertically in the final image. This leaves 50 pixels margin above and below the bounding box for a total height of 2700 pixels.\n",
        "* **crop_width and crop_height**: Define the final output image dimensions, maintaining a 3:4 aspect ratio.\n",
        "\n",
        "\n",
        "```\n",
        "INPUT_FOLDER = 'input_images'\n",
        "OUTPUT_FOLDER = 'output_images'\n",
        "```\n",
        "\n",
        "* INPUT_FOLDER: Specifies the folder containing images to process.\n",
        "* OUTPUT_FOLDER: Specifies where the processed images will be saved.\n",
        "The working_images subfolder stores intermediate results, such as bounding box annotations and upscaled images.\n",
        "\n",
        "# Intermediate Steps and Notes\n",
        "The processing pipeline generates intermediate outputs for debugging and visualization:\n",
        "\n",
        "\n",
        "1. **Bounding Boxes**: Stored in the working_images folder, these images show how the system detects and annotates persons.\n",
        "2. **Upscaled Images**: Use bicubic interpolation for resizing:\n",
        "\n",
        "```\n",
        "upscaled_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "```\n",
        "\n",
        "* **Note**: AI-based upscaling (e.g., Real-ESRGAN) was considered but omitted due to:\n",
        " * GPU requirements.\n",
        " * Longer processing times.\n",
        " * Image artifacts and loss of detail in textures like linen or silk.\n",
        "\n",
        " Future enhancements may replace this step with a more efficient AI-based method, ensuring better quality while maintaining acceptable performance."
      ],
      "metadata": {
        "id": "RIvH7GqIX_2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#final code\n",
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Global variables\n",
        "# Desired box height for scaling\n",
        "desired_box_height = 2600\n",
        "# Crop dimensions maintaining a 3:4 aspect ratio\n",
        "crop_width = 1920\n",
        "crop_height = 2700\n",
        "INPUT_FOLDER = 'input_images'\n",
        "OUTPUT_FOLDER = 'output_images'\n",
        "\n",
        "# Utility functions\n",
        "def visualize_image(image, comment):\n",
        "    \"\"\"Display an image with a comment.\"\"\"\n",
        "    print(comment)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for visualization\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def save_image_with_bounding_box(image, box, output_path, comment=\"\"):\n",
        "    \"\"\"Draw a bounding box on the image and save it.\"\"\"\n",
        "    x_min, y_min, box_width, box_height = box\n",
        "    img_with_box = image.copy()\n",
        "    cv2.rectangle(img_with_box, (x_min, y_min), (x_min + box_width, y_min + box_height), (0, 255, 0), 2)\n",
        "    cv2.imwrite(output_path, img_with_box)\n",
        "    print(f\"{comment} {output_path}\")\n",
        "\n",
        "def detect_person_with_yolo(image):\n",
        "    \"\"\"Detect a person in the image using YOLO.\"\"\"\n",
        "    try:\n",
        "        model = YOLO('yolov8n.pt')  # Use YOLOv8 nano model\n",
        "        results = model(image)\n",
        "        for result in results[0].boxes.data.tolist():\n",
        "            x_min, y_min, x_max, y_max, confidence, class_id = result\n",
        "            if int(class_id) == 0:  # Class \"person\" in YOLO\n",
        "                box_width = int(x_max - x_min)\n",
        "                box_height = int(y_max - y_min)\n",
        "                return [int(x_min), int(y_min), box_width, box_height]\n",
        "        return None  # No person found\n",
        "    except Exception as e:\n",
        "        print(f\"Error finding person with YOLO: {e}\")\n",
        "        return None\n",
        "\n",
        "def calculate_scaling_factor(box_height):\n",
        "    \"\"\"Calculate the scaling factor to achieve the desired bounding box height.\"\"\"\n",
        "    return desired_box_height / box_height\n",
        "\n",
        "def crop_image_to_center(image, box):\n",
        "    \"\"\"Crop the image around the bounding box, centering it.\"\"\"\n",
        "    x_min, y_min, box_width, box_height = box\n",
        "    center_x = x_min + box_width // 2\n",
        "    center_y = y_min + box_height // 2\n",
        "    crop_center_x = crop_width // 2\n",
        "    crop_center_y = crop_height // 2\n",
        "    offset_x = center_x - crop_center_x\n",
        "    offset_y = center_y - crop_center_y\n",
        "\n",
        "    crop_x_min = max(0, offset_x)\n",
        "    crop_y_min = max(0, offset_y)\n",
        "    crop_x_max = min(crop_x_min + crop_width, image.shape[1])\n",
        "    crop_y_max = min(crop_y_min + crop_height, image.shape[0])\n",
        "    crop_x_min = crop_x_max - crop_width\n",
        "    crop_y_min = crop_y_max - crop_height\n",
        "\n",
        "    return image[crop_y_min:crop_y_max, crop_x_min:crop_x_max]\n",
        "\n",
        "# Main processing functions\n",
        "def process_image(input_path, output_folder, working_folder):\n",
        "    \"\"\"Process a single image: detect, upscale, crop, and save intermediate results.\"\"\"\n",
        "    if not os.path.isfile(input_path):\n",
        "        print(f\"Error: File {input_path} does not exist.\")\n",
        "        return\n",
        "\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    os.makedirs(working_folder, exist_ok=True)\n",
        "\n",
        "    base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
        "    img = cv2.imread(input_path)\n",
        "    if img is None:\n",
        "        print(f\"Error: Unable to read the file {input_path}.\")\n",
        "        return\n",
        "\n",
        "    person_box = detect_person_with_yolo(img)\n",
        "    if not person_box:\n",
        "        print(\"Error: No person detected.\")\n",
        "        return\n",
        "\n",
        "    save_image_with_bounding_box(img, person_box, os.path.join(working_folder, f\"{base_name}_step1_bounding_box.jpg\"), \"Saved image with bounding box:\")\n",
        "\n",
        "    scaling_factor = calculate_scaling_factor(person_box[3])\n",
        "    new_width = int(img.shape[1] * scaling_factor)\n",
        "    new_height = int(img.shape[0] * scaling_factor)\n",
        "    upscaled_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    person_box = detect_person_with_yolo(upscaled_img)\n",
        "    save_image_with_bounding_box(upscaled_img, person_box, os.path.join(working_folder, f\"{base_name}_step2_upscaled_bounding_box.jpg\"), \"Saved upscaled image with bounding box:\")\n",
        "\n",
        "    cropped_img = crop_image_to_center(upscaled_img, person_box)\n",
        "    cv2.imwrite(os.path.join(working_folder, f\"{base_name}_step3_cropped_image.jpg\"), cropped_img)\n",
        "    print(f\"Saved cropped image: {os.path.join(working_folder, f'{base_name}_step3_cropped_image.jpg')}\")\n",
        "\n",
        "    cv2.imwrite(os.path.join(output_folder, f\"{base_name}.jpg\"), cropped_img)\n",
        "    print(f\"Final processed image saved as: {os.path.join(output_folder, f'{base_name}.jpg')}\" )\n",
        "\n",
        "def process_images_in_folder(input_folder, output_folder):\n",
        "    \"\"\"Process all images in the input folder and organize results.\"\"\"\n",
        "    if not os.path.exists(input_folder):\n",
        "        print(f\"Error: Input folder {input_folder} does not exist.\")\n",
        "        return\n",
        "\n",
        "    working_folder = os.path.join(output_folder, \"working_images\")\n",
        "    os.makedirs(working_folder, exist_ok=True)\n",
        "\n",
        "    for file_name in os.listdir(input_folder):\n",
        "        input_path = os.path.join(input_folder, file_name)\n",
        "        if os.path.isfile(input_path):\n",
        "            process_image(input_path, output_folder, working_folder)\n",
        "\n",
        "# Main function\n",
        "process_images_in_folder(INPUT_FOLDER, OUTPUT_FOLDER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R6OE93WwxWs",
        "outputId": "d4a983e9-d3f0-42d5-e612-3de4eca1b02b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 268.5ms\n",
            "Speed: 29.1ms preprocess, 268.5ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Saved image with bounding box: output_images/working_images/depositphotos_509201804-stock-photo-business-man-in-shirt-with_step1_bounding_box.jpg\n",
            "\n",
            "0: 384x640 1 person, 202.0ms\n",
            "Speed: 7.8ms preprocess, 202.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Saved upscaled image with bounding box: output_images/working_images/depositphotos_509201804-stock-photo-business-man-in-shirt-with_step2_upscaled_bounding_box.jpg\n",
            "Saved cropped image: output_images/working_images/depositphotos_509201804-stock-photo-business-man-in-shirt-with_step3_cropped_image.jpg\n",
            "Final processed image saved as: output_images/depositphotos_509201804-stock-photo-business-man-in-shirt-with.jpg\n"
          ]
        }
      ]
    }
  ]
}